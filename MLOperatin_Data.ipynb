{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j6ZPyIkgJVHUjqclRYMttKwxIceXebKj",
      "authorship_tag": "ABX9TyPh+LrpPIHBVr7N/ORJEwd9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra-ynp/MLOperation-FinalProject/blob/main/MLOperatin_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Exploration and Validation"
      ],
      "metadata": {
        "id": "B_esdv54Tq7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1: Load and Inspect the Dataset"
      ],
      "metadata": {
        "id": "Eu7qfZ1pT5Wh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckt7wTuXsPb2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"HR.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\nDataset Describe:\")\n",
        "print(data.describe())\n",
        "\n",
        "print(\"\\nUnique Values per Column:\")\n",
        "print(data.nunique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 Handle Missing Values\n"
      ],
      "metadata": {
        "id": "O4vi9BAoGe5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "TlTn5-edGBLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3: Analyze and Visualize Features\n"
      ],
      "metadata": {
        "id": "h-kXi10uGULF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical features\n",
        "numerical_columns = ['satisfaction_level', 'last_evaluation', 'number_project',\n",
        "                     'average_montly_hours', 'time_spend_company']\n",
        "for column in numerical_columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(data[column], kde=True, bins=20)\n",
        "    plt.title(f\"Distribution of {column}\")\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RKhlHcg3GBrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical features\n",
        "categorical_columns = ['sales', 'salary']\n",
        "for column in categorical_columns:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    sns.countplot(data=data, x=column, hue=\"left\")  # \"left\" indicates resignation\n",
        "    plt.title(f\"{column} Distribution by Resignation (left)\")\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d7aseCjcGB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap for numerical features\n",
        "ndata = data[data.columns[:-2]]\n",
        "# print(ndata.head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "correlation_matrix = ndata.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lKSD9YN-HmTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4: Check for Data Quality Issues"
      ],
      "metadata": {
        "id": "9WGGc_08NvYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = data.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
        "\n",
        "# Outliers detection (boxplot)\n",
        "for column in numerical_columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(x=data[column])\n",
        "    plt.title(f\"Outliers in {column}\")\n",
        "    plt.xlabel(column)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "o3a024ZgL61s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for inconsistencies in categorical columns\n",
        "print(\"\\nChecking for inconsistent values in categorical columns:\")\n",
        "for column in categorical_columns:\n",
        "    print(f\"Unique values in '{column}':\")\n",
        "    print(data[column].unique())"
      ],
      "metadata": {
        "id": "4nBIQsEnPSRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5: Target Variable Analysis"
      ],
      "metadata": {
        "id": "4u8zfqPrP_Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the target variable (left)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=data, x=\"left\")\n",
        "plt.title(\"Target Variable Distribution (Resignation)\")\n",
        "plt.xlabel(\"Resigned (1 = Yes, 0 = No)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_We3WyB4P-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Wrangling"
      ],
      "metadata": {
        "id": "S663YmJJTv69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Handle Missing Values"
      ],
      "metadata": {
        "id": "8GMQQu1E1KUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# sns.heatmap(data.isnull(), cbar=False, cmap=\"viridis\")\n",
        "# plt.title(\"Missing Values Heatmap\")\n",
        "# plt.show()\n",
        "\n",
        "#There is no missing value"
      ],
      "metadata": {
        "id": "CfU_aCmJ539T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Feature Engineering and Encoding"
      ],
      "metadata": {
        "id": "AFVQA9d21NtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variables\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_array = encoder.fit_transform(data[categorical_columns])\n",
        "\n",
        "encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
        "encoded_data = pd.DataFrame(encoded_array, columns=encoded_columns)\n",
        "encoded_data.index = data.index\n",
        "\n",
        "# Drop original categorical columns and concatenate with encoded columns\n",
        "data_encoded = data.drop(columns=categorical_columns).reset_index(drop=True)\n",
        "data_final = pd.concat([data_encoded, encoded_data], axis=1)\n",
        "\n",
        "print(\"\\nData After Encoding:\")\n",
        "print(data_final.head())"
      ],
      "metadata": {
        "id": "PAjMq9iD1Ib2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Data Splitting"
      ],
      "metadata": {
        "id": "5wySnO3ReHkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) and Target (y)\n",
        "X = data_final.drop('left', axis=1)\n",
        "y = data_final['left']\n",
        "\n",
        "# Step 1: Split into Training (70%) and Temp (30%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Step 2: Split Temp into Validation (15%) and Test (15%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "6P980yWe7sLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 Scaling Numerical Features"
      ],
      "metadata": {
        "id": "bbYmELddmQzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
        "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
        "X_val[numerical_columns] = scaler.transform(X_val[numerical_columns])\n",
        "\n",
        "print(\"\\nScaled Numerical Features in Training Data:\")\n",
        "print(X_train[numerical_columns].head())"
      ],
      "metadata": {
        "id": "GCmQX34AmUcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Address Class Imbalance"
      ],
      "metadata": {
        "id": "ooMUfNwHrQy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nClass Distribution After SMOTE:\")\n",
        "print(y_train_resampled.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CfR_iItrRug",
        "outputId": "01e92792-cfd5-430f-c4d9-fa7fb301a258"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After SMOTE:\n",
            "left\n",
            "0    7999\n",
            "1    7999\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}